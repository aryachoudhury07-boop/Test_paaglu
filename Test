import streamlit as st
from langchain_openai import ChatOpenAI
import httpx

# -------------------------------
# 1. Initialize HTTP client
# -------------------------------
client = httpx.Client(verify=False)

# -------------------------------
# 2. Initialize LLM
# -------------------------------
llm = ChatOpenAI(
    base_url="https://genailab.tcs.in",   # your endpoint
    model="azure_ai/genailab-maas-DeepSeek-V3-0324",
    api_key="sk-xxxxxx",  # ğŸ”‘ replace with your API key
    http_client=client,
    temperature=0.7
)

# -------------------------------
# 3. Streamlit UI
# -------------------------------
st.set_page_config(page_title="AI Chatbot", page_icon="ğŸ¤–")
st.title("ğŸ’¬ AI Chatbot (with Context)")

# Initialize session state for messages
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "You are a helpful AI assistant. Answer clearly."}
    ]

# Display chat history
for msg in st.session_state.messages:
    if msg["role"] == "user":
        with st.chat_message("user"):
            st.write(msg["content"])
    elif msg["role"] == "assistant":
        with st.chat_message("assistant"):
            st.write(msg["content"])

# User input box
if user_input := st.chat_input("Type your message..."):
    # Add user message
    st.session_state.messages.append({"role": "user", "content": user_input})

    # Display user message
    with st.chat_message("user"):
        st.write(user_input)

    # Get LLM response
    response = llm.invoke(st.session_state.messages)
    reply = response.content

    # Add assistant message
    st.session_state.messages.append({"role": "assistant", "content": reply})

    # Display assistant message
    with st.chat_message("assistant"):
        st.write(reply)
